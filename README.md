# Project_Titanic
Week 2 Project

Introduction to ML Kaggle Titanic passenger survival prediction challenge https://www.kaggle.com/c/titanic/overview.

Topics introduced and discussed:
- Machine Learning: Supervised, Unsupervised, Classification, Regression, Overfitting/Underfitting, test/train split
- Classification: Logistic Regression, Scikit Learn
- Evaluating Classifiers: Accuracy, Precision, Recall, ROC and AUC, True/False Positive/Negatives, Confusion Matrices
- ML steps to follow
- Feature Engineering: Normalising/Scaling, Imputation, Interpolation, One-hot Encoding, Mapping, adding Features, Interaction terms, Feature Selection
- Cross Validation: K-fold Cross Validation, Test/Train Split, Overfitting, Bootstrapping
- Tree-based Models: Decision Trees, Random Forests, Gradient Boosting
- Hyperparameters: Optimising,
- Support Vector Machines: SVCs
- Ensembles and Pipelines
